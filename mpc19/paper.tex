% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads,a4paper]{llncs}
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\usepackage{proof}
\usepackage{amsmath}
%\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{fancyvrb}

\usepackage{tikzit}
\input{figures/stringdiagrams.tikzstyles}

\usepackage{soul}


\newcommand{\N}{\mathbb{N}}
\newcommand{\Pio}{\ensuremath{\mathsf{\Pi}^{\mathsf{o}}}} 
\newcommand{\Set}{\mathsf{Set}}
\newcommand{\Par}{\mathsf{Par}}
\newcommand{\comp}{\circ}
% \newcommand{\U}{\mathcal{U}}
\newcommand{\copair}[2]{[#1,#2]}
\newcommand{\pair}[2]{\left< #1,#2 \right>}
\newcommand{\inl}{\mathsf{inl}}
\newcommand{\inr}{\mathsf{inr}}
\newcommand{\fst}{\mathsf{fst}}
\newcommand{\snd}{\mathsf{snd}}
\newcommand{\T}{\mathsf{T}}
\newcommand{\Inv}{\mathsf{Inv}}
\newcommand{\iter}{\mathsf{iter}}
\newcommand{\mapL}[1]{#1_{\mathsf{L}}}
\newcommand{\mapR}[1]{#1_{\mathsf{R}}}

% Syntax Pi0
\newcommand{\Ty}{\mathsf{Ty}}
\newcommand{\Var}{\mathsf{Var}}
\newcommand{\id}{\mathsf{id}}
\newcommand{\lr}{\longleftrightarrow}
\newcommand{\fold}{\mathsf{fold}}
\newcommand{\unfold}{\mathsf{unfold}}
\newcommand{\sub}{\mathsf{sub}}
\newcommand{\trace}{\ensuremath{\mathsf{trace}}}
\newcommand{\Z}{\mathsf{Z}}
\newcommand{\I}{\mathsf{I}}
\newcommand{\LR}{\iff}
\renewcommand{\dagger}{\mathsf{dagger}}

% Delay macros
\newcommand{\Delay}{\ensuremath{\mathsf{Delay}\,}}
\newcommand{\Maybe}{\mathsf{Maybe}}
\newcommand{\now}{\mathsf{now}}
\newcommand{\later}{\mathsf{later}}
\newcommand{\laterR}{\mathsf{laterR}}
\newcommand{\laterL}{\mathsf{laterL}}
\newcommand{\never}{\mathsf{never}}
\newcommand{\dn}{\downarrow}
\newcommand{\bind}{\mathsf{bind}}
\newcommand{\str}{\mathsf{str}}
\newcommand{\costr}{\mathsf{costr}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\Dapprox}{\mathbb{D}_{\approx}}
\newcommand{\copairD}[2]{[#1,#2]_{\D}}
\newcommand{\pairD}[2]{\left< #1,#2 \right>_{\D}}
\newcommand{\inlD}{\mathsf{inl}_{\D}}
\newcommand{\inrD}{\mathsf{inr}_{\D}}
\newcommand{\fstD}{\mathsf{fst}_{\D}}
\newcommand{\sndD}{\mathsf{snd}_{\D}}
\newcommand{\piso}{\mathsf{isPartialIso}}
\newcommand{\pisoalt}{\mathsf{isPartialIso}_2}
\newcommand{\iterD}{\mathsf{iter}_\D}
\newcommand{\unfolding}{\mathsf{unfolding}}
\newcommand{\refl}{\mathsf{refl}}
\newcommand{\traceD}{\mathsf{trace}_\D}
\newcommand{\traceHD}{\mathsf{traceH}_\D}
\newcommand{\daggerD}{\mathsf{dagger}_\D}
\newcommand{\Orb}[3]{\mathsf{Orb}\,#1\,#2\,#3}
\newcommand{\done}{\mathsf{done}}
\renewcommand{\next}{\mathsf{next}}
\newcommand{\reverseOrbit}{\mathsf{reverseOrb}}

\newcommand{\todo}[1]{\hl{TODO: #1}}
\newcommand{\todocite}[1]{\hl{[TODO: #1]}}

\begin{document}
%
\title{En garde! Unguarded iteration for reversible computation in the Delay monad\thanks{Supported by organization x.}}
%
\titlerunning{Unguarded iteration for reversible computation in the Delay monad}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Robin Kaarsgaard \inst{1}\orcidID{0000-0002-7672-799X} \and
Niccol\`o Veltri\inst{2}\orcidID{0000-0002-7230-3436}}
%
\authorrunning{Kaarsgaard and Veltri}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{DIKU, Department of Computer Science, University of
    Copenhagen\\ \email{robin@di.ku.dk} \and
Department of Computer Science, IT University of
    Copenhagen\\ \email{nive@itu.dk}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Reversible computation studies computations which exhibit both forward and
backward determinism. Among others, it has been studied for half a century for
its applications in low-power computing, and forms the basis for quantum
computing.

Though certified program equivalence is useful for a number of applications
(e.g., certified compilation and optimization), little work on this topic has
been carried out for reversible programming languages. As a notable exception,
Carette and Sabry have studied the equivalences of the finitary fragment of \Pio, a reversible combinator calculus, yielding a two-level calculus of type isomorphisms and equivalences between them.

In this paper, we extend the two-level calculus of finitary \Pio{} to one for
full \Pio{} (i.e., with both recursive types and iteration by means of a
\trace{} combinator) using the \Delay{} monad, which can be regarded as a
``computability-aware'' analogue of the usual $\mathsf{Maybe}$ monad for
partiality. This yields a calculus of iterative (and possibly non-terminating)
reversible programs acting on user-defined dynamic data structures together
with a calculus of certified program equivalences between these programs.

\keywords{reversible computation \and iteration \and delay monad}
\end{abstract}

\section{TODO} % (fold)
\label{sec:todo}
Robin:
\begin{itemize}
  \item Conclusion
  \begin{itemize}
    \item Related work: Kleisli category of the Delay monad is a join
    restriction category, inverse category of a join restriction category is a
    join inverse category; already known to be dagger-traced under certain
    conditions.
    \item Future work: Semantics of time invertible programming. Extension of
    the work on the Kleisli category of the Delay monad beyond $\Set$ to other
    (more general) categories, e.g. topoi.
  \end{itemize}
\end{itemize}
Niccol√≤: 
\begin{itemize}
  \item Fix the syntax to be closer to ordinary presentations (but do describe 
  how it is realized in Agda).
  \item Finish the section about trace and iteration.
  \item Remind the reader about double lines of coinductive definitions.
  \item Swap types in Elgot iterator.
\end{itemize}
Both:
\begin{itemize}
  \item \textbf{Important:} Come up with a punnier title! (Something about 
  delays and daggers).
\end{itemize}
% section todo (end)

\section{Introduction}\label{sec:intro}
Reversible computation is an emerging computation paradigm encompassing
computations that are not just deterministic when executed the \emph{forward}
direction, but also in the \emph{backward} direction. While this may seem
initially obscure, reversible computation forms the basis for quantum
computing, and has seen applications in a number of different areas such as
low-power computing~\cite{Landauer61}, robotics~\cite{SchultzLE18}, discrete
event simulation~\cite{Schordan15}, and the simultaneous construction of
parser/pretty printer pairs~\cite{RendelO10}. Like classical computing, it has
its own automata~\cite{Bennett73}, circuit model~\cite{DeVos10}, machine
architectures~\cite{ThomsenAG11}, programming
languages~\cite{JamesS12,JamesS14,YokoyamaG07,Schultz18,JacobsenKT18}, semantic
metalanguages~\cite{Giles,KaarsgaardAG17,KaarsgaardG18}, and so on.

\Pio{} is a family of reversible combinator calculi comprising structural
isomorphisms and combinators corresponding to those found in dagger-traced
$\omega$-continuous rig categories~\cite{Karvonen19}. Though superficially
simple, \Pio{} is expressive enough as a metalanguage to give semantics to the
typed reversible functional programming language Theseus~\cite{JamesS14}.

In \cite{CaretteS16}, the authors studied the equivalences of isomorphisms in
the finitary fragment of \Pio{} (i.e., without recursive types and iteration
via the \trace{} combinator), and showed that these equivalences could be
adequately described by another combinator calculus of equivalences of
isomorphisms, in sum yielding a two-level calculus of isomorphisms and
equivalences of isomorphisms. In this paper, we build on this work to produce a
(fully formalized) two-level calculus for full \Pio{} (supporting both recursive
types and iteration) via the \Delay{} monad, using insights gained from the
study of its Kleisli category~\cite{UustaluV17,ChapmanUV19,VeltriPhD}, as well
as of join inverse categories in which reversible iteration may be
modelled~\cite{KaarsgaardAG17}.

The coinductive delay datatype was introduced by Capretta
\cite{Capretta05} as a way of defining possibly non-terminating
functions in Martin-L\"of type theory. It has found a number of
applications, ranging from operational semantics of functional
languages \cite{Danielsson12} to formalization of domain theory in
type theory \cite{BentonKV09} and normalization by evaluation
\cite{AbelC14}. Here we employ it for giving denotational semantics to
\Pio. In particular, we show how to endow the delay datatype with a
dagger trace combinator, whose construction factors through the
specification of a uniform iteration operator
\cite{GoncharovSRJ18,GoncharovMR16}.

Throughout the paper, we reason constructively in Martin-L\"of type
theory. Classically, the delay monad is isomorphic to the maybe monad
$\Maybe\,X \equiv X + 1$,
and thus just a complication of something that can be expressed much
simpler. Constructively, however, they are very different. In particular,
it is impossible to define a well-behaved trace combinator for the
maybe monad without assuming classical principles such as the law of
excluded middle.


We have fully formalized the development of the paper in the
dependently typed programming language Agda~\cite{Agda}. The code is
available online at \\ \texttt{\url{https://github.com/niccoloveltri/pi0-agda}}. The
formalization uses Agda 2.6.0.


\paragraph{The type-theoretical framework}

Our work is settled in Martin-L\"of type theory with inductive and
coinductive types. We write $(a : A) \to B \,a$ for dependent function
spaces and $(a : A) \times B \,a$ for dependent products. We allow
dependent functions to have implicit arguments and indicate implicit
argument positions with curly brackets (as in Agda). We use the
symbol $=$ for definitional equality of terms and $\equiv$ for
propositional equality. Given $f : A \to C$ and
$g : B \to C$, we write $\copair f g : A + B \to C$ for their
copairing. The coproduct injections are denoted $\inl$ and $\inr$.
Given $h : C \to A$ and $k : C \to B$, we write
$\pair h k : C \to A \times B$ for their pairing. The product
projections are denoted $\fst$ and $\snd$. The empty type is 0 and the
empty type is 1. We write $\Set$ for the category of
types and functions between them.
We define $A \leftrightarrow B = (A \to B) \times (B \to A)$.
%We write $\U$ for the universe of (small) types.

We do not assume uniqueness of identity proofs
(UIP), i.e. we do not consider two proofs of $x \equiv y$ necessarily
equal. Agda natively supports UIP, so we have to manually switch it
using the \verb|without-K| option.

In Section \ref{sec:delay}, we will need to quotient a certain type by
an equivalence relation. Martin-L\"of type theory does not support
quotient types, but quotients can be simulated using setoids
\cite{BartheCP03}. Alternatively, we can consider extensions of type theory with
quotient types \`a la Hofmann \cite{Hofmann}, such as homotopy type
theory \cite{Hott}. Setoids and quotient types \`a la
Hofmann are not generally equivalent approaches, but they are indeed
equivalent for the constructions we develop in this work. Therefore,
in the rest of the paper we assume the existence of quotient types and
we refrain from technical discussions on their implementation.


\section{Syntax of \Pio}\label{sec:syntax}

In this section, we present the syntax of \Pio. The 1-structure of
\Pio, i.e. its types and terms, has originaly been introduced by James
and Sabry \cite{JamesS12}. In particular, we include the presence of
recursive types and a primitive trace combinator.  Following Carette
and Sabry's formalization of the finitary fragment of \Pio, we
consider a collection of equivalences between terms. Our list of
axioms notably differs from theirs in that we do not require each term to be
a total isomorphism, we ask only for the existence of a partial
inverse. 

Formally, the collection of types of \Pio\ correspond to those naturally
interpreted in dagger traced $\omega$-continuous rig categories (see
\cite{Karvonen19}).

\subsection{Types}

The types of \Pio\ are given by the grammar:
\[
A ::= \Z \, | \,A \oplus A \, | \,\I \,| \,A \otimes A \,| \,X \,|
\,\mu X.A 
\]
where $X$ ranges over a set of variables. In Agda, we use de Bruijn
indexes to deal with type variables, so the grammar above is formally
realized by the rules in Figure \ref{fig:types}. The type $\Ty\,n$
represents \Pio\ types containing at most $n$ free
variables. Variables themselves are encoded as elements of
$\mathsf{Fin}\,n$, the type of natural numbers strictly smaller then
$n$. Notice that the $\mu$ binds a variable, which, for $A : \Ty\,(n +
1)$, we consider to be $n + 1$.

\begin{figure}
\[
\arraycolsep=8pt\def\arraystretch{2.8}
\begin{array}{ccc}
%\hline 
\infer{\Z : \Ty\,n}{} 
& \infer{\I : \Ty\,n}{}
& \infer{\Var\,i : \Ty\,n}{i : \mathsf{Fin}\,n}  \\
\infer{A \oplus B : \Ty\,n}{A : \Ty\,n & B : \Ty\,n}
& \infer{A \otimes B : \Ty\,n}{A : \Ty\,n & B : \Ty\,n}
& \infer{\mu A : \Ty\,n}{A : \Ty\,(n+1)} 
%\\ \hline
\end{array}
\]
\caption{Types of \Pio, as formalized in Agda}
\label{fig:types}
\end{figure}

It is also necessary to define substitutions. In Agda, given
types $A : \Ty\,(n+1)$ and $B : \Ty\,n$, we construct
$\sub\,A\,B : \Ty\,n$ to represent the substituted type $A[B/X]$,
where $X$ corresponds to the $(n+1)$-th variable in context.



\subsection{Terms}

The terms of \Pio\ are inductively generated by the rules in Figure
\ref{fig:programs}. They include the identity programs $\id$ and
sequential composition of programs $\bullet$. $(\Z,\oplus)$ is a
symmetric monoidal structure, with terms $\lambda_\oplus$,
$\alpha_\oplus$ and $\sigma_\otimes$ as structural
morphisms. Similarly for $(\I,\otimes)$. Moreover $\otimes$
distributes over $\Z$ and $\oplus$ from the right, as evidenced by  $\kappa$
and $\delta$. Elements of $\mu X.A$ are built using the term
constructor $\fold$ and destructed with $\unfold$. Finally, we find the
$\trace$ combinator. 


\begin{figure}
\[
\arraycolsep=7pt\def\arraystretch{1.8}
\begin{array}{cc}%{|cc|}
%\hline 
\id : A \lr A
& \infer{g \bullet f : A \lr C}{g : B \lr C & f : A \lr B} \\ [.25cm]
\infer{f \oplus g : A \oplus B \lr C \oplus D}{f : A \lr C & g : B \lr D} 
& \infer{f \otimes g : A \otimes B \lr C \otimes D}{f : A \lr C & g : B \lr D} \\
\lambda_{\oplus} : \Z \oplus A \lr A
& \lambda_{\oplus}^{-1} : A \lr \Z \oplus A\\
\lambda_{\otimes} : \I \otimes A \lr A
& \lambda_{\otimes}^{-1} : A \lr \I \otimes A\\
\alpha_{\oplus} : (A \oplus B) \oplus C \lr A \oplus (B \oplus C)
& \alpha_{\oplus}^{-1} : A \oplus (B \oplus C) \lr (A \oplus B) \oplus C \\
\alpha_{\otimes} : (A \otimes B) \otimes C \lr A \otimes (B \otimes C)
& \alpha_{\otimes}^{-1} : A \otimes (B \otimes C) \lr (A \otimes B) \otimes C \\
\sigma_{\oplus} : A \oplus B \lr B \oplus A
& \sigma_{\otimes} : A \otimes B \lr B \otimes A \\
\kappa : \Z \otimes A \lr \Z 
& \delta : (A \oplus B) \otimes C \lr (A \otimes C) \oplus (B \otimes C) \\
\kappa^{-1} : \Z \lr \Z \otimes A
& \delta^{-1} : (A \otimes C) \oplus (B \otimes C)  \lr (A \oplus B) \otimes C \\
\fold : A[\mu X.A/X] \lr \mu X.A
& \unfold : \mu X.A \lr A[\mu X.A/X] \\[.25cm]
\multicolumn{2}{c}{\infer{\trace \,f: A \lr B}{f : A \oplus C \lr B \oplus C}} \\
%\hline
\end{array}
\]
\caption{Terms of \Pio}
\label{fig:programs}
\end{figure}

\begin{figure}
\[
\arraycolsep=8pt\def\arraystretch{1.8}
\begin{array}{cc} %{|cc|} \hline 
\multicolumn{2}{c}{\mathsf{naturality_L} : f \bullet \trace\,g \LR \trace\,((f \oplus
  \id) \bullet g)} \\ 
\multicolumn{2}{c}{\mathsf{naturality_R} : \trace\,g \bullet f \LR \trace\,(g \bullet (f 
  \oplus \id))} \\  
\multicolumn{2}{c}{\mathsf{dinaturality} : \trace \,((\id \oplus f) \bullet g) \LR \trace
  \,(g \bullet (\id \oplus f))} \\
\multicolumn{2}{c}{\mathsf{vanishing_\oplus} : \trace \,f \LR \trace \,(\trace
  \,(\alpha_\oplus^{-1} \bullet f \bullet \alpha_\oplus))} \\ 
\mathsf{vanishing_\Z} : f \LR \rho_\oplus^{-1} \bullet \trace \,f
  \bullet \rho_\oplus 
&
\mathsf{yanking} : \trace \sigma_\oplus \LR \id
 \\
\multicolumn{2}{c}{\mathsf{tracePIso} : \trace\,f \bullet \trace\,(\dagger\,f)
  \bullet \trace\,f \LR \trace \,f} \\
%%  \\[.25cm]
%% \multicolumn{2}{c}{\infer{\mathsf{tracePIso}\,p : \trace\,f \bullet \trace\,(\dagger\,f)
%%   \bullet \trace\,f \LR \trace \,f}{p : f \bullet \dagger\,f \bullet
%%   f \LR f}} \\
\mathsf{foldIso} : \fold \bullet \unfold \LR \id 
&
\mathsf{unfoldIso} : \unfold \bullet \fold \LR \id
\\
\multicolumn{2}{c}{\mathsf{uniquePIso} : f \bullet \dagger \,f
  \bullet g \bullet \dagger \, g \LR g \bullet \dagger \,g
  \bullet f \bullet \dagger \, f}
%\\ \hline
\end{array}
\]
\caption{Selection of term equivalences of \Pio}
\label{fig:programequivs}
\end{figure}

Every \Pio\ program is reversible. The (partial) inverse of a program is given by
the function $\dagger : (A \lr B) \to (B \lr A)$, recursively defined
as follows:

\[
\begin{array}{llcll}
%\multicolumn{2}{l}{\dagger : \{A B : \Ty \,n\} \to A \lr B \to B \lr A} \\
\dagger \,\id &= \id & \quad &
\dagger\, (g \bullet f) & = \dagger\, f \bullet \dagger\, g \\
\dagger\, (f \oplus g) & = \dagger\, f \oplus \dagger\, g & \quad &
\dagger\, (f \otimes g) & = \dagger\, f \otimes \dagger\, g \\
\dagger\, \lambda_\oplus ^{-1} & = \lambda_\oplus & \quad &
\dagger\, \lambda_\oplus & = \lambda_\oplus^{-1} \\
\dagger\, \sigma_\oplus & = \sigma_\oplus & \quad &
\dagger\, \alpha_\oplus & = \alpha_\oplus^{-1} \\
\dagger\, \alpha_\oplus^{-1} & = \alpha_\oplus & \quad &
\dagger\, \lambda_\otimes & = \lambda_\otimes^{-1} \\
\dagger\, \lambda_\otimes ^{-1} & = \lambda_\otimes & \quad &
\dagger\, \sigma_\otimes & = \sigma_\otimes \\
\dagger\, \alpha_\otimes & = \alpha_\otimes^{-1} & \quad &
\dagger\, \alpha_\otimes^{-1} & = \alpha_\otimes \\
\dagger\, \kappa & = \kappa^{-1} & \quad &
\dagger\, \kappa^{-1} & = \kappa \\
\dagger\, \delta & = \delta^{-1} & \quad &
\dagger\, \delta^{-1} & = \delta \\
\dagger\, \fold & = \unfold & \quad &
\dagger\, \unfold & = \fold \\
\dagger\, (\trace \,f) & = \trace \,(\dagger\, f)
\end{array}
\]

The $\dagger$ operation is involutive. Notice that this property holds
up to propositional equality. This is proved by induction on the term
$f$.
\[
\mathsf{daggerInvol} : (f : A \lr B) \to \dagger \,(\dagger\,f) \equiv f
\]

The right unitor for $\oplus$ is given by $\rho_\oplus = \lambda_\oplus \bullet
\sigma_\oplus : A \oplus \Z \lr A,$ and $\rho_\otimes$ is defined similarly.
Analogously, we can derive the left distributors $\kappa' : A \otimes \Z
\lr A$ and $\delta' : A \otimes (B \oplus C) \lr (A \otimes B) \oplus
(A \otimes C)$.


%% \infer{\lambda_{\oplus} : \Z \oplus A \lr A}{}
%% & \infer{\lambda_{\oplus}^{-1} : A \lr \Z \oplus A}{} \\
%% \infer{\lambda_{\otimes} : \I \otimes A \lr A}{}
%% & \infer{\lambda_{\otimes}^{-1} : A \lr \I \otimes A}{} \\
%% \infer{\alpha_{\oplus} : (A \oplus B) \oplus C \lr A \oplus (B \oplus C)}{}
%% & \infer{\alpha_{\oplus}^{-1} : A \oplus (B \oplus C) \lr (A \oplus B) \oplus C}{} \\
%% \infer{\alpha_{\otimes} : (A \otimes B) \otimes C \lr A \otimes (B \otimes C)}{}
%% & \infer{\alpha_{\otimes}^{-1} : A \otimes (B \otimes C) \lr (A \otimes B) \otimes C}{} \\
%% \infer{\sigma_{\oplus} : A \oplus B \lr B \oplus A}{}
%% & \infer{\sigma_{\otimes} : A \otimes B \lr B \otimes A}{} \\
%% \infer{\kappa : \Z \otimes A \lr \Z}{} 
%% & \infer{\delta : (A \oplus B) \otimes C \lr (A \otimes C) \oplus (B \otimes C)}{} \\
%% \infer{\kappa^{-1} : \Z \lr \Z \otimes A}{}
%% & \infer{\delta^{-1} : (A \otimes C) \oplus (B \otimes C)  \lr (A \oplus B) \otimes C}{} \\
%% \infer{\fold : \sub \, A \, (\mu \,A) \lr \mu \,A}{} 
%% & \infer{\unfold : \mu\,A \lr \sub \, A \, (\mu \,A)}{} \\
%% \multicolumn{2}{c}{\infer{\trace \,f: A \lr B}{f : A \oplus C \lr B \oplus C}} \\

\subsection{Term Equivalences}

A selection of term equivalences of \Pio\ is given in Figure
\ref{fig:programequivs}. We only include the equivalences that either
differ or have not previously considered by Carette and Sabry in their
formalization of the finite fragment of \Pio \cite{CaretteS16}. In
particular, we leave out the long list of Laplaza's coherence axioms
expressing that the types of \Pio\ form a rig category \cite{Laplaza}.
We also omit the equivalences stating that $\lambda_\oplus^{-1}$ is
the total inverse of $\lambda_\oplus$, similarly for the other
structural morphisms. 

The list of term equivalences in Figure \ref{fig:programequivs}
contains the trace axioms, displaying that the types of \Pio\ form a
traced monoidal category wrt. the additive monoidal structure
$(\Z,\oplus)$ \cite{Karvonen19}. Next we ask for
$\trace\,(\dagger\,f)$ to be the partial inverse of
$\trace\,f$. Remember that we have defined $\dagger\,(\trace\,f)$ to
be $\trace\,(\dagger \,f)$, so the axiom $\mathsf{tracePIso}$
is evidence that the trace combinator of \Pio\ is a dagger trace.
Afterwards we have two equivalences stating that $\unfold$ is the
total inverse of $\fold$. 

It is possible to show that every term $f$ has $\dagger\,f$ as its partial
inverse, and since the final equivalence of Figure~\ref{fig:programequivs} is
equivalent to stating that partial inverses are unique~\cite{Kastl79}, it
follows that the types and terms of \Pio\ form an inverse category. The proof
proceeds by induction on $f$.
\[
\mathsf{existsPIso} : (f : A \lr B) \to f \bullet \dagger\,f
\bullet\,f \LR f
\]

\section{Delay Monad}\label{sec:delay}

The coinductive delay datatype was first introduce by Capretta for
representing general recursive functions in Martin-L\"of type theory
\cite{Capretta05}.  Given a type $A$, elements of $\Delay A$ are
possibly non-terminating ``computations'' returning a value of $A$
whenever they terminate. Formally, $\Delay A$ is defined as a
coinductive type with the following introduction rules:
\[
\infer{\now\,a : \Delay A}{a : A}
\quad
\infer={\later\,x : \Delay A}{x : \Delay A}
\]
The constructor $\now$ embeds $A$ into $\Delay A$, so $\now\,a$
represents the terminating computation returning the value $a$. The
constructor $\later$ adds an additional unit of time delay to a
computation. Double rule lines refer to a coinductive constructor,
which can be applied an infinite amount of times.
The non-terminating computation $\never$
is corecursively defined as $\never = \later \,\never$.

The delay datatype is a monad. The unit is the constructor $\now$,
while the Kleisli extension $\bind$ is corecursively defined as follows:
\begin{align*}
& \bind : (A \to \Delay B) \to \Delay A \to \Delay B \\
& \bind \,f \, (\now\,a) = f\,a \\
& \bind\,f\,(\later\,x) = \later\,(\bind\,f\,x)
\end{align*}
The delay monad, like any other monad on $\Set$, has a unique strength
operation which we denote by $\str : A \times \Delay B \to \Delay (A
\times B)$. Similarly, it has a unique costrength operation $\costr :
\Delay A \times B \to \Delay (A \times B)$ definable using $\str$. Moreover, the delay datatype is a commutative monad.

The Kleisli category of the delay monad, that we call $\D$, has types
as objects and functions $f : A \to \Delay B$ as morphisms between $A$
and $B$. In $\D$, the identity map on an object $A$ is the constructor
$\now$, while the composition of morphisms $f : A \to \Delay B$ and $g
: B \to \Delay C$ is given by $f \diamond g = \bind\,f \comp g$.

The delay datatype allows us to program with partial functions, but
the introduced notion of partiality is intensional, in the sense that
computations terminating with the same value in a different number of
steps are considered different. To obtain an extensional notion of
partiality, which in particular allows the specification of a
well-behaved trace operator, we introduce the notion of termination-sensitive
weak bisimilarity.

Weak bisimilarity is defined in terms of convergence. A computation
$x : \Delay A$ converges to $a : A$ if it terminates in a finite
number of steps returning the value $a$. When this happens, we write
$x \dn a$. The relation $\dn$ is inductively defined by the rules:
\[
\infer{\now\,a \dn a}{}
\quad
\infer{\later\,x \dn a}{x \dn a}
\]
Two computations in $\Delay A$ are weakly bisimilar if they differ by
a finite number of applications of the constructor $\later$. This
informal statement can be formalized in several different but
logically equivalent ways \cite{ChapmanUV19}. 
A possible defintion is as follows:
\begin{equation}\label{eq:weak1}
x \approx y = (a : A) \to x \dn a \leftrightarrow y \dn a
\end{equation}
The definition says that $x$ and $y$ are weakly bisimilar if, whenever
$x$ terminates returning a value $a$, then $y$ also terminates
returning $a$, and vice versa.
Alternatively, weak bisimilarity can be coinductively formulated as follows:
\begin{equation}
\label{eq:weak2}
\arraycolsep=8pt\def\arraystretch{2.8}
\begin{array}{cc}
\infer{\now_{\approx}  : \now\,a \approx \now\,a}{}
&
\infer={\later_{\approx} \,p : \later\,x_1 \approx \later\,x_2}{p : x_1 \approx x_2}
\\
\infer{\laterL_{\approx} \, p: \later\,x \approx \now\,a}{p : x \approx \now \,a}
&
\infer{\laterR_{\approx} \, p: \now\,a \approx \later\,x}{p : \now\,a \approx x}
\end{array}
\end{equation}
Notice that the constructor $\later_{\approx}$ is
coinductive. Formulation (\ref{eq:weak1}) and (\ref{eq:weak2}) are
logically equivalent, meaning that two computations are weakly
bisimilar as in (\ref{eq:weak1}) if and only if they are weakly
bisimilar as in (\ref{eq:weak2}).
In the rest of the paper we will employ
both encodings of weak bisimilarity, in each case explicitly stating
if we are working with definition (\ref{eq:weak1}) or definition (\ref{eq:weak2}).
Weak bisimilarity is an equivalence
relation and it is a congruence w.r.t. the $\later$ operation.
For example, here is a proof that weak bisimilarity is reflexive,
employing definition (\ref{eq:weak2}).
\begin{align*}
& \refl_{\approx} : \{x : \Delay A\} \to x \approx x \\
& \refl_{\approx} \,\{\now\,a\} = \now_\approx \\
& \refl_{\approx} \,\{\later\,x\} = \later_\approx\,(\refl_\approx \,\{x\})
\end{align*}

We call $\Dapprox$ the category $\D$ with homsets
quotiented by pointwise weak bisimilarity. This means that in
$\Dapprox$ two morphisms $f$ and $g$ are considered equal whenever
$f \, a \approx g \, a$, for all inputs $a$. When this is the case, we
also write $f \approx g$. 

As an alternative to quotienting the homsets of $\D$, we could have
quotiented the delay datatype by weak bisimilarity:
$\mathsf{Delay}_{\approx}\,A = \Delay A/{\approx}$. In previous work
\cite{ChapmanUV19}, we showed that this construction has problematic
consequences if we employ Hofmann's approach to quotient types
\cite{Hofmann}. For example, it does not seem possible to lift the
monad structure of $\Delay$ to $\mathsf{Delay}_{\approx}$ without
postulating additional principles such as the axiom of countable
choice. More fundamentally for this work, countable choice would be
needed for modelling the trace operator of \Pio\ in the Kleisli
category of $\mathsf{Delay}_{\approx}$. Notice that, if the setoid approach
to quotienting is employed, the latter constructions go through
without the need for additional assumptions. In order to keep an
agnostic perspective on quotient types and avoid the need for
disputable semi-classical choice principles, we decided to quotient
the homsets of $\D$ by (poitwise) weak bisimilarity instead of the
delay datatype.

\subsection{Finite Products and Coproducts}
\label{sec:prod}

Colimits in $\Dapprox$ are inherited from $\Set$. This means that 0 is
also the initial object of $\Dapprox$, similarly $A + B$ is the
binary coproduct of $A$ and $B$ in $\Dapprox$. Given $f : A \to
\Delay C$ and $g : B \to \Delay C$, we define their copairing as
$\copairD f g = \copair f g : A + B \to \Delay C$. The operation
$\copairD - -$ is compatible with weak bisimilarity, in the sense that
$\copairD{f_1}{g_1} \approx \copairD{f_2}{g_2}$ whenever $f_1 \approx f_2$
and $g_1 \approx g_2$.
The coproduct
injections are given by $\inlD = \now \comp \inl : A \to \Delay (A +
B)$ and $\inrD = \now \comp \inr : B \to \Delay (A + B)$.


Just as limits in $\Set$ do not lift to limits in the category $\Par$ of sets
and partial functions, they do not lift to $\Dapprox$ either. This is not an
issue with these concrete formulations of partiality, but rather with the
interaction of partiality (in the sense of restriction categories) and limits
in general (see \cite[Section 4.4]{CockettL07}). In particular, $1$ is not
terminal object and $A \times B$ is not the binary product of $A$ and $B$ in
$\Dapprox$. In fact, $0$ is (also) the terminal object, with $\lambda \_.\,
\never : A \to \Delay 0$ as the terminal morphism. The
binary product of $A$ and $B$ in $\Dapprox$ is given by
$A + B + A \times B$. Nevertheless, it is possible to prove that 1 and
$- \times -$ are partial terminal object and partial binary products
respectively, in the sense of Cockett and Lack's restriction
categories \cite{CockettL02,CockettL07}. Here we refrain from making the latter
statement formal. We only show the construction of the partial pairing
operation, which we employ in the interpretation of \Pio.  Given
$f : C \to \Delay A$ and $g : C \to \Delay B$, we define:
\begin{align*}
& \pairD f g : C \to \Delay (A \times B) \\
& \pairD f g = \costr \diamond (\str \comp \pair f g)
\end{align*}
Since the delay monad is commutative, the function $\pairD f g$ is
equal to $\str \diamond (\costr \comp \pair f g)$. The operation
$\pairD - -$ is compatible with weak bisimilarity.

\subsection{Partial Isomorphisms}
\label{sec:isos}

In order to model the reversible programs of \Pio, we need to consider
reversible computations in $\Dapprox$. Given a morphism $f : A \to
\Delay B$, we say that it is a partial isomorphism if the following
type is inhabited:
\begin{align*}
\piso \,f = (g : B \to \Delay A) \times \left( (a : A) (b : B) \to  f
  \,a \dn b \leftrightarrow g \,b \dn a  \right)  
\end{align*}
In other words, $f$ is a partial isomorphism if there exists a
morphism $g : B \to \Delay A$ such that, if $f\,a$ terminates
returning a value $b$, then $g\,b$ terminates returning $a$, and vice
versa. Given a partial isomorphism $f$, we denote its partial inverse
by $\daggerD\,f$.

In $\Dapprox$, our definition of partial isomorphisms is equivalent to
the standard categorical one~\cite{Kastl79} (see also \cite{CockettL02}),
which, translated in our type-theoretical setting, is
\begin{align*}
\pisoalt \,f = (g : B \to \Delay A) \times f \diamond g \diamond
  f \approx f \times g \diamond f \diamond g \approx g 
\end{align*}
We denote $A \simeq B$ the type of partial isomorphisms between
$A$ and $B$:
\[
A \simeq B = (f : A \to \Delay B) \times \piso \,f
\]
We call $\Inv \Dapprox$ the subcategory of $\Dapprox$ consisting of
(equivalence classes of) partial isomorphisms. Note that $\Inv\Dapprox$
inherits neither partial products nor coproducts of $\Dapprox$, as the
universal mapping property fails in both cases. However, it can be shown that
in the category $\Inv\Dapprox$, $0$ is a zero object, $A + B$ is the
disjointness tensor product of $A$ and $B$ (in the sense of Giles~\cite{Giles})
with unit $0$, and $A \times B$ a monoidal product of $A$ and $B$ with unit $1$
(though it is \emph{not} an inverse product in the sense of
Giles~\cite{Giles}, as that would imply decidable equality on all objects).

%%  In this work we do not formally construct
%% the quotients $(A \to \Delay B)/{\approx}$, since we work in a type
%% theory without quotient types. 
%% % Instead we require that every construction we perform on morphisms in
%% % $\Dapprox$ respects weak bisimilarity.
%% Instead, we represent the homsets of $\Dapprox$ as setoids.a category
%% enriched in setoids \cite{BartheCP03}: $\Dapprox$ has the same objects
%% of $\D$, but morphisms between $A$ and $B$ form a setoid $(A \to
%% \Delay B, {\approx})$. This implies that every function we
%% define out of the type $A \to \Delay B$ must respects weak
%% bisimilarity. 


%% In previous work \cite{ChapmanUV19} we showed that, when working in a
%% type theory with quotient types a la Hofmann \cite{Hofmann}, quotienting the
%% delay monad by weak bisimilarity has problematic consequences. For example,
%% it does not seem possible to recover the monad structure on the
%% quotiented datatype $\mathsf{DelayQuot}\,A = \Delay A/{\approx}$
%% without assuming non-constructive principles
%% such as the axiom of countable choice. More fundamentally for this
%% work, countable choice would be needed for modelling the trace operator of \Pio. In
%% loc.cit. we showed that a possible way to avoid these issues is
%% forming the quotients of homsets, as in $(A \to \Delay B)/{\approx}$, instead of
%% quotienting the delay datatype directly. 


\section{Elgot Iteration}\label{sec:elgot}

An Elgot monad \cite{GoncharovMR16,GoncharovSRJ18} is a monad $T$
whose Kleilsi category supports unguarded uniform iteration. More
precisely\footnote{Here we give the definition of Elgot monad on
  $\Set$, but the definition of Elgot monad makes sense in any
  category with binary coproducts.}, a monad $\T$ is Elgot if there
exists an operation
\[
\iter_\T : (A \to \T \,(B + A)) \to A \to \T\,B
\]
satisfying a number of axioms, most notably the unfolding axiom:
\[
\iter_\T\,f \equiv \copair {\eta_\T}{\iter_\T \,f} \diamond_\T f
\]
where $\eta_\T$ is the unit of $\T$ and $\diamond_\T$ denotes morphism
composition in the Kleisli category of $\T$.

The delay monad is an Elgot monad for which the axioms holds up to
weak bisimilarity, not propositional equality. Its iteration operator
relies on the definition of an auxiliary function $\iterD'$
corecursively defined as follows:
\[ %\arraycolsep=8pt
\def\arraystretch{1.2}
\begin{array}{ll}
\multicolumn{2}{l}{\iterD' : (A \to \Delay (B + A)) \to \Delay (B + A) \to \Delay B} \\
\iterD' \,f \,(\now \,(\inl\, b)) &= \now \,b \\
\iterD' \,f \,(\now \,(\inr\, a)) &= \later \,(\iterD' \,f \,(f \,a)) \\
\iterD' \,f \,(\later \,x) &= \later \,(\iterD' \,f \,x) \\
 \\
\multicolumn{2}{l}{\iterD : (A \to \Delay (B + A)) \to A \to \Delay B} \\
\multicolumn{2}{l}{\iterD \,f \,a = \iterD' \,f \,(f \,a)}
\end{array}
\]

%% \begin{align*}
%% & \iterD' : (A \to \Delay (A + B)) \to \Delay (A + B) \to \Delay B \\
%% & \iterD' \,f \,(\now \,(\inl\, a)) = \later \,(\iterD' \,f \,(f \,a)) \\
%% & \iterD' \,f \,(\now \,(\inr\, b)) = \now \,b \\
%% & \iterD' \,f \,(\later \,x) = \later \,(\iterD' \,f \,x) \\ 
%% & \\
%% & \iterD : (A \to \Delay (A + B)) \to A \to \Delay B \\
%% & \iterD \,f \,a = \iterD' \,f \,(f \,a)
%% \end{align*}
The definition above can be given the following intuitive
explaination. If $f\,a$ does not terminate, then $\iterD\,f\,a$ does
not terminate as well. If $f\,a$ terminates, there are two
possibilities: either $f\,a$ converges to $\inr\,b$, in which case
$\iterD\,f\,a$ terminates returning the value $b$; or $f\,a$ converges
to $\inl\,a'$, in which case we repeat the precedure by replacing $a$
with $a'$. Notice that in the latter case we also add one occurrence
of $\later$ to the total computation time. This addition is necessary
for ensuring the productivity of the corecursively defined function
$\iterD'$. In fact, by changing the second line of its specification to
$\iterD' \,f \,(\now \,(\inr\, a)) = \iterD' \,f \,(f a)$
and taking $f = \inrD$, we would have that $\iterD' \,f \,(\now
\,(\inr\, a))$ unfolds indefinitely without producing any output. In
Agda, such a definition would be rightfully rejected by the termination
checker. 

The operation $\iterD$ is compatible with weak bisimilarity, which means
that $\iterD\,f_1 \approx \iterD\,f_2$ whenever $f_1 \approx f_2$.

As mentioned above, $\iterD$ satisfies the Elgot iteration axioms only
up to weak bisimilarity. Here we show the proof of the unfolding
axiom. We employ the definition (\ref{eq:weak2}) of weak
bisimilarity. The proof relies on an auxiliary proof $\unfolding'$. 
\[
\def\arraystretch{1.2}
\begin{array}{ll}
\multicolumn{2}{l}{\unfolding' : (f : A \to \Delay (B + A)) \to
  \bind\, \copairD {\now}{\iterD \,f} \approx \iterD' \,f} \\
\unfolding' \,f \,(\now \,(\inl \,b)) & = \now_\approx \\
\unfolding' \,f \,(\now \,(\inr \,a)) & = \laterR_{\approx} \,
  \refl_\approx \\
\unfolding' \,f \,(\later \,x) & = \later_\approx \,(\unfolding'\, f\,
  x) \\
 \\
\multicolumn{2}{l}{\unfolding : (f : A \to \Delay (B + A)) \to
  \copairD {\now}{\iterD \,f}\diamond f \approx \iterD \,f}\\
\multicolumn{2}{l}{\unfolding \,f\,x = \unfolding'\,f\,(f\,x)}
\end{array}
\]




\subsection{Trace}\label{sec:trace}

From the Elgot iteration operator it is possible to derive a trace
operator. First, given $f : A + B \to C$, we introduce
$\mapL f = f \comp \inl : A \to C$ and
$\mapR f = f \comp \inr : B \to C$, so that $f = [\mapL f , \mapR f]$.
Graphically:
\ctikzfig{fL_fR}
 
The trace operator in $\Dapprox$ is defined as follows:
\begin{align*}
& \traceD : (A + C \to \Delay (B + C)) \to A \to \Delay B \\
& \traceD \,f = \copairD{\now}{\iterD \,\mapR f}\diamond \mapL f
\end{align*}
The operation $\traceD$ is compatible with weak bisimilarity. 
Pictorially:

\ctikzfig{trace}

Intuitively, the function $\mapL f$ initialises the loop. It either
diverges, so that the trace of $f$ diverges as well, or it terminates. It either terminates with
an element $b : B$, in which case the loop ends immediately returning
$b$, or it converges to a value $c : C$, and in this case we proceed
by  invoking the iteration of $\mapR f$ on $c$.

It is well-known that a trace operator is obtainable from an iteration
operator, as shown by Hasegawa~\cite{Hasegawa97}. His construction,
instantiated to our setting, looks as follows:
\begin{align*}
& \traceHD : (A + C \to \Delay (B + C)) \to A \to \Delay B \\
& \traceHD \,f = \iterD (\Delay (\id + \inr) \comp f) \comp \inl
\end{align*}
or graphically
\ctikzfig{trace_hasegawa}

It is not difficult to prove that the two possible ways of defining a
trace operator from Elgot iteration are equivalent, in the sense that
$\traceD\,f \approx \traceHD\,f$ for all $f : A + C \to \Delay (B +
C)$. 

The trace axioms follow from the Elgot iteration axioms.

\subsection{Dagger Trace}\label{sec:daggertrace}

We now move to show that $\traceD$ is a dagger trace operator,
i.e. if $f$ is a partial isomorphism, then
$\traceD\,f$ is also a partial isomorphism with partial inverse $\traceD\,(\daggerD\,f)$.

This is proved by introducing the notion of \emph{orbit} of an element
$x : A + C$ wrt. a function $f : A + C \to \Delay (B + C)$. The orbit of
$x$ consists of the terms of type $B + C$ that are obtained in a
finite number of steps from repeated applications of the function $f$
on $x$. Formally, a term $y$ belongs to the orbit of $f$ wrt. $x$ if
the type $\Orb f x y $ is inhabited, with the latter type
inductively defined as: 
\[
\infer{\done\,p : \Orb f x y}{p : f \,x \dn y}
\qquad 
\infer{\next\,p \,q : \Orb f x y}{p : f \,x \dn \inr\,c & q : \Orb f
  {(\inr\,c)} y}
\]

The notion of orbit can be used to state when 
the iteration of a function $f : A \to \Delay (B + A)$ on a input
$a : A$ terminates with value $b : B$.
\[
\iterD\,f\,a \dn b \leftrightarrow \Orb {\copairD{\inlD}{f}} {(\inr\,a)} {(\inl\,b)}
\]
We refer the interested reader to our Agda formalization for a complete
proof of this logical equivalence.
Similarly, the orbit can be used to state when 
the trace of a function $f : A + C \to \Delay (B + C)$ on a input
$a : A$ terminates with value $b : B$.
\begin{equation}\label{eq:traceorbit}
\traceD\,f\,a \dn b \leftrightarrow \Orb f{(\inl\,a)} {(\inl\,b)}
\end{equation}

Showing that $\traceD$ is a dagger trace operator requires the
construction of an inhabitant of $\traceD\,f\,a \dn b \leftrightarrow
\traceD\,(\daggerD\,f)\,b \dn a$. Thanks to the logical equivalence in
(\ref{eq:traceorbit}), this is equivalent to prove the following
statement instead: 
\[
\Orb f {(\inl\,a)} {(\inl\,b)} \leftrightarrow \Orb {(\daggerD\,f)} {(\inl\,b)} {(\inl\,a)}
\]
We give a proof of the left-to-right direction, the other implication
is proved in an analogous way.  Notice that a term
$p : \Orb f {(\inl\,a)} {(\inl\,b)}$ can be seen as a finite sequence
of elements of $C$, precisely the intermediate values produced by
$\traceD\,f\,a$ before converging to $b$. The orbit of $b$ wrt. the
partial inverse of $f$ can therefore be computed by reversing the
sequence of elements present in $p$. The construction of the reverse
of an orbit is very similar to the way the reverse of a list is
typically defined in a functional programming language like Haskell.
We first consider an intermediate value $c : C$ and we assume to have
already reversed the initial section of the orbit between $\inl\,a$
and $\inr\,c$, that is a term $p' : \Orb  {(\daggerD\,f)} {(\inr\,c)}
{(\inl\,a)}$. 
\[
\def\arraystretch{1.2}
\begin{array}{lll}
\multicolumn{3}{l}{\reverseOrbit' : (i : \{a : A\} \{b : B\} \to f \,a
\dn b \to \daggerD\,f  \,b \dn a) \to } \\
\multicolumn{3}{l}{\qquad \{a : A\} \{b : B\} \{c : C\} \to } \\
\multicolumn{3}{l}{\qquad \Orb f {(\inr\,c)}
 {(\inl\,b)} \to \Orb  {(\daggerD\,f)} {(\inr\,c)} {(\inl\,a)} \to } \\
\multicolumn{3}{l}{\qquad \Orb  {(\daggerD\,f)} {(\inl\,b)} {(\inl\,a)}}\\
\reverseOrbit' \,i\, (\done \,p) & p'&= \next\, (i \,p)\,p' \\
\reverseOrbit' \,i\,(\next\,p\,q) & p'&= \reverseOrbit' \,i\,q \,(\next \,(i\,p)\,p')
\end{array}
\]
The proof of $\reverseOrbit'$ proceeds by structural induction on the final
segment of the orbit between $\inr\,c$ and $\inl\,b$ that still needs
to be reversed, which is the argument of type
$\Orb f {(\inr\,c)} {(\inl\,b)}$. There are two possibilities.
\begin{itemize}
\item We have $p : f\,(\inr\,c) \dn
\inl\,b$, in which case $i\,p : \daggerD\,f\,(\inl\,b) \dn
\inl\,c$. Then we return $\next\,(i\,p)\,p'$.
\item There exists another value $c' : C$ such that $p :
  f\,(\inr\,c) \dn \inr\,c'$ and $q : \Orb f {(\inr\,c')}
  {(\inl\,b)}$. Then we recursively invoke the function
  $\reverseOrbit' \,i$ on arguments $q$ and $\next\,(i\,p)\,p' : \Orb
  {(\daggerD \,f)} {(\inr\,c')} {(\inl\,b)}$.
\end{itemize}

The reverse of an orbit is derivable using the auxiliary function $\reverseOrbit'$.
\[
\def\arraystretch{1.2}
\begin{array}{ll}
\multicolumn{2}{l}{\reverseOrbit : (i : \{a : A\} \{b : B\} \to f \,a
  \dn b \to \daggerD\,f  \,b \dn a) \to} \\
\multicolumn{2}{l}{\qquad \{a : A\} \{b : B\} \to} \\
\multicolumn{2}{l}{\qquad \Orb f {(\inl\,a)}
  {(\inl\,b)} \to \Orb  {(\daggerD\,f)} {(\inl\,b)} {(\inl\,a)}}\\
\reverseOrbit \,i\, (\done \,p) &= \done \, (i \,p) \\
\reverseOrbit \,i\,(\next\,p\,q) &= \reverseOrbit' \,i\,q \,(\done \,(i\,p))
\end{array}
\]
The proof of $\reverseOrbit$ proceeds bystructural induction on the
orbit of type
$\Orb f {(\inl\,a)} {(\inl\,b)}$. There are two possibilities.
\begin{itemize}
\item We have $p : f\,(\inl\,a) \dn
\inl\,b$, in which case $i\,p : \daggerD\,f\,(\inl\,b) \dn
\inl\,a$. Then we return $\done\,(i\,p)$.
\item There exists a value $c : C$ such that $p :
  f\,(\inl\,a) \dn \inr\,c$ and $q : \Orb f {(\inr\,c)}
  {(\inl\,b)}$. We conclude by invoking the function
  $\reverseOrbit' \,i$ on arguments $q$ and $\done\,(i\,p) : \Orb
  {(\daggerD \,f)} {(\inr\,c)} {(\inl\,a)}$.
\end{itemize}


\section{Soundness}\label{sec:interpretation}

\section{Conclusions}


%
%
%
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{paper}

\end{document}
