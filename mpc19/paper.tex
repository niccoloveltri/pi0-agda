% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\usepackage{proof}
\usepackage{amsmath}
%\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{fancyvrb}

\usepackage{tikzit}
\input{figures/stringdiagrams.tikzstyles}

\usepackage{soul}


\newcommand{\N}{\mathbb{N}}
\newcommand{\Pio}{$\mathsf{\Pi}^{\mathsf{o}}$} 
\newcommand{\Set}{\mathsf{Set}}
\newcommand{\Par}{\mathsf{Par}}
\newcommand{\comp}{\circ}
\newcommand{\U}{\mathcal{U}}
\newcommand{\copair}[2]{[#1,#2]}
\newcommand{\pair}[2]{\left< #1,#2 \right>}
\newcommand{\inl}{\mathsf{inl}}
\newcommand{\inr}{\mathsf{inr}}
\newcommand{\fst}{\mathsf{fst}}
\newcommand{\snd}{\mathsf{snd}}
\newcommand{\T}{\mathsf{T}}
\newcommand{\Inv}{\mathsf{Inv}}
\newcommand{\iter}{\mathsf{iter}}
\newcommand{\mapL}[1]{#1_{\mathsf{L}}}
\newcommand{\mapR}[1]{#1_{\mathsf{R}}}


% Syntax Pi0
\newcommand{\Ty}{\mathsf{Ty}}
\newcommand{\Var}{\mathsf{Var}}
\newcommand{\id}{\mathsf{id}}
\newcommand{\lr}{\longleftrightarrow}
\newcommand{\fold}{\mathsf{fold}}
\newcommand{\unfold}{\mathsf{unfold}}
\newcommand{\sub}{\mathsf{sub}}
\newcommand{\trace}{\mathsf{trace}}
\newcommand{\Z}{\mathsf{Z}}
\newcommand{\I}{\mathsf{I}}

% Delay macros
\newcommand{\Delay}{\mathsf{Delay}\,}
\newcommand{\now}{\mathsf{now}}
\newcommand{\later}{\mathsf{later}}
\newcommand{\laterR}{\mathsf{laterR}}
\newcommand{\laterL}{\mathsf{laterL}}
\newcommand{\never}{\mathsf{never}}
\newcommand{\dn}{\downarrow}
\newcommand{\bind}{\mathsf{bind}}
\newcommand{\str}{\mathsf{str}}
\newcommand{\costr}{\mathsf{costr}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\Dapprox}{\mathbb{D}_{\approx}}
\newcommand{\copairD}[2]{[#1,#2]_{\D}}
\newcommand{\pairD}[2]{\left< #1,#2 \right>_{\D}}
\newcommand{\inlD}{\mathsf{inl}_{\D}}
\newcommand{\inrD}{\mathsf{inr}_{\D}}
\newcommand{\fstD}{\mathsf{fst}_{\D}}
\newcommand{\sndD}{\mathsf{snd}_{\D}}
\newcommand{\piso}{\mathsf{isPartialIso}}
\newcommand{\pisoalt}{\mathsf{isPartialIso}_2}
\newcommand{\iterD}{\mathsf{iter}_\D}
\newcommand{\unfolding}{\mathsf{unfolding}}
\newcommand{\refl}{\mathsf{refl}}
\newcommand{\traceD}{\mathsf{trace}_\D}
\newcommand{\traceHD}{\mathsf{traceH}_\D}

\newcommand{\todo}[1]{\hl{TODO: #1}}
\newcommand{\todocite}[1]{\hl{[TODO: #1]}}

\begin{document}
%
\title{Type-theoretical Semantics of \Pio\ via the Delay Monad \thanks{Supported by organization x.}}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Robin Kaarsgaard \inst{1}\orcidID{0000-0002-7672-799X} \and
Niccol\`o Veltri\inst{2}\orcidID{0000-0002-7230-3436}}
%
\authorrunning{Kaarsgaard and Veltri}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{DIKU, Department of Computer Science, University of
    Copenhagen\\ \email{robin@di.ku.dk} \and
Department of Computer Science, IT University of
    Copenhagen\\ \email{nive@itu.dk}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The abstract should briefly summarize the contents of the paper in
150--250 words.

\keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}

\section{TODO} % (fold)
\label{sec:todo}
Robin:
\begin{itemize}
  \item Abstract.
  \item Introduction.
  \item Make pictures! 
  \begin{itemize}
    \item Graphical language of monoidal categories, and for \Pio.
    \item Trace.  
    \item Iterator, iterator unfolding axiom.
    \item Trace from iterator.
  \end{itemize}
  \item Conclusion
  \begin{itemize}
    \item Related work: Kleisli category of the Delay monad is a join
    restriction category, inverse category of a join restriction category is a
    join inverse category; already known to be dagger-traced under certain
    conditions.
    \item Future work: Semantics of time invertible programming. Extension of
    the work on the Kleisli category of the Delay monad beyond $\Set$ to other
    (more general) categories, e.g. topoi.
  \end{itemize}
\end{itemize}
Niccol√≤: 
\begin{itemize}
  \item Fix the syntax to be closer to ordinary presentations (but do describe 
  how it is realized in Agda).
  \item Finish the section about trace and iteration.
  \item Remind the reader about double lines of coinductive definitions. 
\end{itemize}
Both:
\begin{itemize}
  \item \textbf{Important:} Come up with a punnier title! (Something about 
  delays and daggers).
\end{itemize}
% section todo (end)

\section{Introduction}\label{sec:intro}
\todo{RC Motivation.}

\todo{Formalization motivation? Maybe?}

\todo{Explain Carette et al. Say that we are extending it to be actually useful (but don't say it like that).}

\todo{Delay vs. Maybe monad.}

\paragraph{The type-theoretical framework}

Our work is settled in Martin-L\"of type theory with inductive and
coinductive types. We write $(a : A) \to B \,a$ for dependent function
spaces and $(a : A) \times B \,a$ for dependent products. We allow
dependent functions to have implicit arguments and indicate implicit
argument positions with curly brackets (as in Agda). We use the
symbol $=$ for definitional equality of terms and $\equiv$ for
propositional equality. Given $f : A \to C$ and
$g : B \to C$, we write $\copair f g : A + B \to C$ for their
copairing. The coproduct injections are denoted $\inl$ and $\inr$.
Given $h : C \to A$ and $k : C \to B$, we write
$\pair h k : C \to A \times B$ for their pairing. The product
projections are denoted $\fst$ and $\snd$. The empty type is 0 and the
empty type is 1. We write $\Set$ for the category of
types and functions between them.
We define $A \leftrightarrow B = (A \to B) \times (B \to A)$.
%We write $\U$ for the universe of (small) types.

We do not assume uniqueness of identity proofs
(UIP), i.e. we do not consider two proofs of $x \equiv y$ necessarily
equal. Agda natively supports UIP, so we have to manually switch it
using the \verb|without-K| option.

In Section \ref{sec:delay}, we will need to quotient a certain type by
an equivalence relation. Martin-L\"of type theory does not support
quotient types, but quotients can be simulated using setoids
\cite{BartheCP03}. Alternatively, we can consider extensions of type theory with
quotient types \`a la Hofmann \cite{Hofmann}, such as homotopy type
theory \cite{Hott}. Setoids and quotient types \`a la
Hofmann are not generally equivalent approaches, but they are indeed
equivalent for the constructions we develop in this work. Therefore,
in the rest of the paper we assume the existence of quotient types and
we refrain from technical discussions on their implementation.


\section{Syntax of \Pio}\label{sec:syntax}

\subsection{Types}

\[
A ::= \Z \, | \,A \oplus A \, | \,\I \,| \,A \otimes A \,| \,X \,|
\,\mu X.\,A 
\]

%% \begin{figure}
%% \[
%% \arraycolsep=8pt\def\arraystretch{2.8}
%% \begin{array}{|ccc|}
%% \hline 
%% \infer{\Z : \Ty_n}{} 
%% & \infer{\I : \Ty_n}{}
%% & \infer{\Var\,i : \Ty_n}{i \in [0..n)}  \\
%% \infer{A \oplus B : \Ty_n}{A : \Ty_n & B : \Ty_n}
%% & \infer{A \otimes B : \Ty_n}{A : \Ty_n & B : \Ty_n}
%% & \infer{\mu\,A : \Ty_n}{A : \Ty_{n+1}} \\
%% \hline
%% \end{array}
%% \]
%% \caption{Types of \Pio.}
%% \label{fig:types}
%% \end{figure}

\subsection{Programs}

\begin{figure}
\[
\arraycolsep=8pt\def\arraystretch{2.8}
\begin{array}{|cc|}
\hline
\infer{\id : A \lr A}{}
& \infer{g \bullet f : A \lr C}{g : B \lr C & f : A \lr B} \\
\infer{f \oplus g : A \oplus B \lr C \oplus D}{f : A \lr C & g : B \lr D} 
& \infer{f \otimes g : A \otimes B \lr C \otimes D}{f : A \lr C & g : B \lr D} \\
\infer{\lambda_{\oplus} : \Z \oplus A \lr A}{}
& \infer{\lambda_{\oplus}^{-1} : A \lr \Z \oplus A}{} \\
\infer{\lambda_{\otimes} : \I \otimes A \lr A}{}
& \infer{\lambda_{\otimes}^{-1} : A \lr \I \otimes A}{} \\
\infer{\alpha_{\oplus} : (A \oplus B) \oplus C \lr A \oplus (B \oplus C)}{}
& \infer{\alpha_{\oplus}^{-1} : A \oplus (B \oplus C) \lr (A \oplus B) \oplus C}{} \\
\infer{\alpha_{\otimes} : (A \otimes B) \otimes C \lr A \otimes (B \otimes C)}{}
& \infer{\alpha_{\otimes}^{-1} : A \otimes (B \otimes C) \lr (A \otimes B) \otimes C}{} \\
\infer{\sigma_{\oplus} : A \oplus B \lr B \oplus A}{}
& \infer{\sigma_{\otimes} : A \otimes B \lr B \otimes A}{} \\
\infer{\kappa : \Z \otimes A \lr \Z}{} 
& \infer{\delta : (A \oplus B) \otimes C \lr (A \otimes C) \oplus (B \otimes C)}{} \\
\infer{\kappa^{-1} : \Z \lr \Z \otimes A}{}
& \infer{\delta^{-1} : (A \otimes C) \oplus (B \otimes C)  \lr (A \oplus B) \otimes C}{} \\
\infer{\fold : \sub \, A \, (\mu \,A) \lr \mu \,A}{} 
& \infer{\unfold : \mu\,A \lr \sub \, A \, (\mu \,A)}{} \\
\multicolumn{2}{|c|}{\infer{\trace \,f: B \lr C}{f : A \oplus B \lr A \oplus C}} \\
\hline
\end{array}
\]
\caption{Programs of \Pio}
\label{fig:programs}
\end{figure}

\section{Delay Monad}\label{sec:delay}

The coinductive delay datatype was first introduce by Capretta for
representing general recursive functions in Martin-L\"of type theory
\cite{Capretta05}.  Given a type $A$, elements of $\Delay A$ are
possibly non-terminating ``computations'' returning a value of $A$
whenever they terminate. Formally, $\Delay A$ is defined as a
coinductive type with the following introduction rules:
\[
\infer{\now\,a : \Delay A}{a : A}
\quad
\infer={\later\,x : \Delay A}{x : \Delay A}
\]
The constructor $\now$ embeds $A$ into $\Delay A$, so $\now\,a$
represents the terminating computation returning the value $a$. The
constructor $\later$ adds an additional unit of time delay to a
computation. Double rule lines refer to a coinductive constructor,
which can be applied an infinite amount of times.
The non-terminating computation $\never$
is corecursively defined as $\never = \later \,\never$.

The delay datatype is a monad. The unit is the constructor $\now$,
while the Kleisli extension $\bind$ is corecursively defined as follows:
\begin{align*}
& \bind : (A \to \Delay B) \to \Delay A \to \Delay B \\
& \bind \,f \, (\now\,a) = f\,a \\
& \bind\,f\,(\later\,x) = \later\,(\bind\,f\,x)
\end{align*}
The delay monad, like any other monad on $\Set$, has a unique strength
operation which we denote by $\str : A \times \Delay B \to \Delay (A
\times B)$. Similarly, it has a unique costrength operation $\costr :
\Delay A \times B \to \Delay (A \times B)$ definable using $\str$. Moreover, the delay datatype is a commutative monad.

The Kleisli category of the delay monad, that we call $\D$, has types
as objects and functions $f : A \to \Delay B$ as morphisms between $A$
and $B$. In $\D$, the identity map on an object $A$ is the constructor
$\now$, while the composition of morphisms $f : A \to \Delay B$ and $g
: B \to \Delay C$ is given by $f \diamond g = \bind\,f \comp g$.

The delay datatype allows us to program with partial functions, but
the introduced notion of partiality is intensional, in the sense that
computations terminating with the same value in a different number of
steps are considered different. To obtain an extensional notion of
partiality, which in particular allows the specification of a
well-behaved trace operator, we introduce the notion of termination-sensitive
weak bisimilarity.

Weak bisimilarity is defined in terms of convergence. A computation
$x : \Delay A$ converges to $a : A$ if it terminates in a finite
number of steps returning the value $a$. When this happens, we write
$x \dn a$. The relation $\dn$ is inductively defined by the rules:
\[
\infer{\now\,a \dn a}{}
\quad
\infer{\later\,x \dn a}{x \dn a}
\]
Two computations in $\Delay A$ are weakly bisimilar if they differ by
a finite number of applications of the constructor $\later$. This
informal statement can be formalized in several different but
logically equivalent ways \cite{ChapmanUV19}. 
A possible defintion is as follows:
\begin{equation}\label{eq:weak1}
x \approx y = (a : A) \to x \dn a \leftrightarrow y \dn a
\end{equation}
The definition says that $x$ and $y$ are weakly bisimilar if, whenever
$x$ terminates returning a value $a$, then $y$ also terminates
returning $a$, and vice versa.
Alternatively, weak bisimilarity can be coinductively formulated as follows:
\begin{equation}
\label{eq:weak2}
\arraycolsep=8pt\def\arraystretch{2.8}
\begin{array}{cc}
\infer{\now_{\approx}  : \now\,a \approx \now\,a}{}
&
\infer={\later_{\approx} \,p : \later\,x_1 \approx \later\,x_2}{p : x_1 \approx x_2}
\\
\infer{\laterL_{\approx} \, p: \later\,x \approx \now\,a}{p : x \approx \now \,a}
&
\infer{\laterR_{\approx} \, p: \now\,a \approx \later\,x}{p : \now\,a \approx x}
\end{array}
\end{equation}
Notice that the constructor $\later_{\approx}$ is
coinductive. Formulation (\ref{eq:weak1}) and (\ref{eq:weak2}) are
logically equivalent, meaning that two computations are weakly
bisimilar as in (\ref{eq:weak1}) if and only if they are weakly
bisimilar as in (\ref{eq:weak2}).
In the rest of the paper we will employ
both encodings of weak bisimilarity, in each case explicitly stating
if we are working with definition (\ref{eq:weak1}) or definition (\ref{eq:weak2}).
Weak bisimilarity is an equivalence
relation and it is a congruence w.r.t. the $\later$ operation.
For example, here is a proof that weak bisimilarity is reflexive,
employing definition (\ref{eq:weak2}).
\begin{align*}
& \refl_{\approx} : \{x : \Delay A\} \to x \approx x \\
& \refl_{\approx} \,\{\now\,a\} = \now_\approx \\
& \refl_{\approx} \,\{\later\,x\} = \later_\approx\,(\refl_\approx \,\{x\})
\end{align*}

We call $\Dapprox$ the category $\D$ with homsets
quotiented by pointwise weak bisimilarity. This means that in
$\Dapprox$ two morphisms $f$ and $g$ are considered equal whenever
$f \, a \approx g \, a$, for all inputs $a$. When this is the case, we
also write $f \approx g$. 

As an alternative to quotienting the homsets of $\D$, we could have
quotiented the delay datatype by weak bisimilarity:
$\mathsf{Delay}_{\approx}\,A = \Delay A/{\approx}$. In previous work
\cite{ChapmanUV19}, we showed that this construction has problematic
consequences if we employ Hofmann's approach to quotient types
\cite{Hofmann}. For example, it does not seem possible to lift the
monad structure of $\Delay$ to $\mathsf{Delay}_{\approx}$ without
postulating additional principles such as the axiom of countable
choice. More fundamentally for this work, countable choice would be
needed for modelling the trace operator of \Pio\ in the Kleisli
category of $\mathsf{Delay}_{\approx}$. Notice that, if the setoid approach
to quotienting is employed, the latter constructions go through
without the need for additional assumptions. In order to keep an
agnostic perspective on quotient types and avoid the need for
disputable semi-classical choice principles, we decided to quotient
the homsets of $\D$ by (poitwise) weak bisimilarity instead of the
delay datatype.

\subsection{Finite Products and Coproducts}
\label{sec:prod}

Colimits in $\Dapprox$ are inherited from $\Set$. This means that 0 is
also the initial object of $\Dapprox$, similarly $A + B$ is the
binary coproduct of $A$ and $B$ in $\Dapprox$. Given $f : A \to
\Delay C$ and $g : B \to \Delay C$, we define their copairing as
$\copairD f g = \copair f g : A + B \to \Delay C$. The operation
$\copairD - -$ is compatible with weak bisimilarity, in the sense that
$\copairD{f_1}{g_1} \approx \copairD{f_2}{g_2}$ whenever $f_1 \approx f_2$
and $g_1 \approx g_2$.
The coproduct
injections are given by $\inlD = \now \comp \inl : A \to \Delay (A +
B)$ and $\inrD = \now \comp \inr : B \to \Delay (A + B)$.


Just as limits in $\Set$ do not lift to limits in the category $\Par$ of sets
and partial functions, they do not lift to $\Dapprox$ either. This is not an
issue with these concrete formulations of partiality, but rather with the
interaction of partiality (in the sense of restriction categories) and limits
in general (see \cite[Section 4.4]{CockettL07}). In particular, $1$ is not
terminal object and $A \times B$ is not the binary product of $A$ and $B$ in
$\Dapprox$. In fact, $0$ is (also) the terminal object, with $\lambda \_.\,
\never : A \to \Delay 0$ as the terminal morphism. The
binary product of $A$ and $B$ in $\Dapprox$ is given by
$A + B + A \times B$. Nevertheless, it is possible to prove that 1 and
$- \times -$ are partial terminal object and partial binary products
respectively, in the sense of Cockett and Lack's restriction
categories \cite{CockettL02,CockettL07}. Here we refrain from making the latter
statement formal. We only show the construction of the partial pairing
operation, which we employ in the interpretation of \Pio.  Given
$f : C \to \Delay A$ and $g : C \to \Delay B$, we define:
\begin{align*}
& \pairD f g : C \to \Delay (A \times B) \\
& \pairD f g = \costr \diamond (\str \comp \pair f g)
\end{align*}
Since the delay monad is commutative, the function $\pairD f g$ is
equal to $\str \diamond (\costr \comp \pair f g)$. The operation
$\pairD - -$ is compatible with weak bisimilarity.

\subsection{Partial Isomorphisms}
\label{sec:isos}

In order to model the reversible programs of \Pio, we need to consider
reversible computations in $\Dapprox$. Given a morphism $f : A \to
\Delay B$, we say that it is a partial isomorphism if the following
type is inhabited:
\begin{align*}
\piso \,f = (g : B \to \Delay A) \times \left( (a : A) (b : B) \to  f
  \,a \dn b \leftrightarrow g \,b \dn a  \right)  
\end{align*}
In other words, $f$ is a partial isomorphism if there exists a
morphism $g : B \to \Delay A$ such that, if $f\,a$ terminates
returning a value $b$, then $g\,b$ terminates returning $a$, and vice
versa. In $\Dapprox$, our definition of partial isomorphisms is equivalent to
the standard categorical one~\cite{Kastl79} (see also \cite{CockettL02}),
which, translated in our type-theoretical setting, is
\begin{align*}
\pisoalt \,f = (g : B \to \Delay A) \times f \diamond g \diamond
  f \approx f \times g \diamond f \diamond g \approx g 
\end{align*}
We denote $A \simeq B$ the type of partial isomorphisms between
$A$ and $B$:
\[
A \simeq B = (f : A \to \Delay B) \times \piso \,f
\]
We call $\Inv \Dapprox$ the subcategory of $\Dapprox$ consisting of
(equivalence classes of) partial isomorphisms. Note that $\Inv\Dapprox$
inherits neither partial products nor coproducts of $\Dapprox$, as the
universal mapping property fails in both cases. However, it can be shown that
in the category $\Inv\Dapprox$, $0$ is a zero object, $A + B$ is the
disjointness tensor product of $A$ and $B$ (in the sense of Giles~\cite{Giles})
with unit $0$, and $A \times B$ a monoidal product of $A$ and $B$ with unit $1$
(though it is \emph{not} an inverse product in the sense of
Giles~\cite{Giles}, as that would imply decidable equality on all objects).

%%  In this work we do not formally construct
%% the quotients $(A \to \Delay B)/{\approx}$, since we work in a type
%% theory without quotient types. 
%% % Instead we require that every construction we perform on morphisms in
%% % $\Dapprox$ respects weak bisimilarity.
%% Instead, we represent the homsets of $\Dapprox$ as setoids.a category
%% enriched in setoids \cite{BartheCP03}: $\Dapprox$ has the same objects
%% of $\D$, but morphisms between $A$ and $B$ form a setoid $(A \to
%% \Delay B, {\approx})$. This implies that every function we
%% define out of the type $A \to \Delay B$ must respects weak
%% bisimilarity. 


%% In previous work \cite{ChapmanUV19} we showed that, when working in a
%% type theory with quotient types a la Hofmann \cite{Hofmann}, quotienting the
%% delay monad by weak bisimilarity has problematic consequences. For example,
%% it does not seem possible to recover the monad structure on the
%% quotiented datatype $\mathsf{DelayQuot}\,A = \Delay A/{\approx}$
%% without assuming non-constructive principles
%% such as the axiom of countable choice. More fundamentally for this
%% work, countable choice would be needed for modelling the trace operator of \Pio. In
%% loc.cit. we showed that a possible way to avoid these issues is
%% forming the quotients of homsets, as in $(A \to \Delay B)/{\approx}$, instead of
%% quotienting the delay datatype directly. 


\section{Elgot Iteration}\label{sec:elgot}

An Elgot monad is a monad $T$ whose Kleilsi category supports
unguarded Elgot iteration. More precisely\footnote{Here we give the
  definition of Elgot monad on $\Set$, but the definition of Elgot
  monad makes sense in any category with binary coproducts.}, a monad
$\T$ is Elgot if there exists an operation
\[
\iter_\T : (A \to \T \,(A + B)) \to A \to \T\,B
\]
satisfying a number of axioms, most notably the unfolding axiom:
\[
\iter_\T\,f \equiv \copair{\iter_\T \,f}{\eta_\T} \diamond_\T f
\]
where $\eta_\T$ is the unit of $\T$ and $\diamond_\T$ denotes morphism
composition in the Kleisli category of $\T$.

The delay monad is an Elgot monad for which the axioms holds up to
weak bisimilarity, not propositional equality. Its iteration operator
relies on the definition of an auxiliary function $\iterD'$
corecursively defined as follows:
\[ %\arraycolsep=8pt
\def\arraystretch{1.2}
\begin{array}{ll}
\multicolumn{2}{l}{\iterD' : (A \to \Delay (A + B)) \to \Delay (A + B) \to \Delay B} \\
\iterD' \,f \,(\now \,(\inl\, a)) &= \later \,(\iterD' \,f \,(f \,a)) \\
\iterD' \,f \,(\now \,(\inr\, b)) &= \now \,b \\
\iterD' \,f \,(\later \,x) &= \later \,(\iterD' \,f \,x) \\
 \\
\multicolumn{2}{l}{\iterD : (A \to \Delay (A + B)) \to A \to \Delay B} \\
\multicolumn{2}{l}{\iterD \,f \,a = \iterD' \,f \,(f \,a)}
\end{array}
\]

%% \begin{align*}
%% & \iterD' : (A \to \Delay (A + B)) \to \Delay (A + B) \to \Delay B \\
%% & \iterD' \,f \,(\now \,(\inl\, a)) = \later \,(\iterD' \,f \,(f \,a)) \\
%% & \iterD' \,f \,(\now \,(\inr\, b)) = \now \,b \\
%% & \iterD' \,f \,(\later \,x) = \later \,(\iterD' \,f \,x) \\ 
%% & \\
%% & \iterD : (A \to \Delay (A + B)) \to A \to \Delay B \\
%% & \iterD \,f \,a = \iterD' \,f \,(f \,a)
%% \end{align*}
The definition above can be given the following intuitive
explaination. If $f\,a$ does not terminate, then $\iterD\,f\,a$ does
not terminate as well. If $f\,a$ terminates, there are two
possibilities: either $f\,a$ converges to $\inr\,b$, in which case
$\iterD\,f\,a$ terminates returning the value $b$; or $f\,a$ converges
to $\inl\,a'$, in which case we repeat the precedure by replacing $a$
with $a'$. Notice that in the latter case we also add one occurrence
of $\later$ to the total computation time. This addition is necessary
achieving the productivity of the corecursively defined function
$\iterD'$. In fact, by changing the first line of its specification to
$\iterD' \,f \,(\now \,(\inl\, a)) = \iterD' \,f \,(f a)$
and taking $f = \inlD$, we would have that $\iterD' \,f \,(\now
\,(\inl\, a))$ unfolds indefinitely without producing any output. In
Agda, such a definition would be rightfully rejected by the termination
checker. 

The operation $\iterD$ is compatible with weak bisimilarity, which means
that $\iterD\,f_1 \approx \iterD\,f_2$ whenever $f_1 \approx f_2$.

As mentioned above, $\iterD$ satisfies the Elgot iteration axioms only
up to weak bisimilarity. Here we show the proof of the unfolding
axiom. We employ the definition (\ref{eq:weak2}) of weak
bisimilarity. The proof relies on an auxiliary proof $\unfolding'$. 
\[
\def\arraystretch{1.2}
\begin{array}{ll}
\multicolumn{2}{l}{\unfolding' : (f : A \to \Delay (A + B)) \to
  \bind\, \copairD{\iterD \,f}{\now} \approx \iterD' \,f} \\
\unfolding' \,f \,(\now \,(\inl \,a)) & = \laterR_{\approx} \,
  \refl_\approx \\
\unfolding' \,f \,(\now \,(\inr \,b)) & = \now_\approx \\
\unfolding' \,f \,(\later \,x) & = \later_\approx \,(\unfolding'\, f\,
  x) \\
 \\
\multicolumn{2}{l}{\unfolding : (f : A \to \Delay (A + B)) \to \copairD{\iterD
  \,f}{\now} \diamond f \approx \iterD \,f}\\
\multicolumn{2}{l}{\unfolding \,f\,x = \unfolding'\,f\,(f\,x)}
\end{array}
\]

\subsection{Trace}\label{sec:trace}

From the Elgot iteration operator it is possible to derive a trace
operator. First, given $f : A + B \to C$, we introduce
$\mapL f = f \comp \inl : A \to C$ and
$\mapR f = f \comp \inr : B \to C$, so that $f = [\mapL f , \mapR f]$.
The trace operator in $\Dapprox$ is defined as follows:
\begin{align*}
& \traceD : (A + B \to \Delay (A + C)) \to B \to \Delay C \\
& \traceD \,f = \copairD{\iterD \,\mapL f}{\now} \diamond \mapR f
\end{align*}
The operation $\traceD$ is compatible with weak bisimilarity. 

It is well-known that a trace operator is obtainable from an iteration
operator. This is how Hasegawa's construction  \cite{Hasegwa97} derives it in the following way:
\begin{align*}
& \traceD : (A + B \to \Delay (A + C)) \to B \to \Delay C \\
& \traceD \,f = \copairD{\iterD \,\mapL f}{\now} \diamond \mapR f
\end{align*}


\subsection{Dagger Trace}\label{sec:daggertrace}

%\ctikzfig{language}


\section{Interpretation}\label{sec:interpretation}

\section{Conclusions}


%
%
%
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{paper}

\end{document}
